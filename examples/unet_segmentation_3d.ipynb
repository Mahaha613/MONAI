{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MONAI version: 0.0.1\nPython version: 3.8.1 (default, Jan  8 2020, 22:29:32)  [GCC 7.3.0]\nNumpy version: 1.18.1\nPytorch version: 1.4.0\nIgnite version: 0.3.0\n"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# assumes the framework is found here, change as necessary\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "import monai.data.transforms.compose as transforms\n",
    "from monai import application, data, networks, utils\n",
    "from monai.data.readers import NiftiDataset\n",
    "from monai.data.transforms import AddChannel, Transpose, Rescale, ToTensor, UniformRandomPatch, GridPatchDataset\n",
    "from monai.networks.metrics.mean_dice import MeanDice\n",
    "from monai.utils.stopperutils import stopping_fn_from_metric\n",
    "\n",
    "\n",
    "application.config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_image_3d(height, width, depth, numObjs=12, radMax=30, noiseMax=0.0, numSegClasses=5):\n",
    "    '''Return a noisy 3D image and segmentation.'''\n",
    "    image = np.zeros((width, height,depth))\n",
    "\n",
    "    for i in range(numObjs):\n",
    "        x = np.random.randint(radMax, width - radMax)\n",
    "        y = np.random.randint(radMax, height - radMax)\n",
    "        z = np.random.randint(radMax, depth - radMax)\n",
    "        rad = np.random.randint(5, radMax)\n",
    "        spy, spx, spz = np.ogrid[-x:width - x, -y:height - y, -z:depth - z]\n",
    "        circle = (spx * spx + spy * spy + spz * spz) <= rad * rad\n",
    "\n",
    "        if numSegClasses > 1:\n",
    "            image[circle] = np.ceil(np.random.random() * numSegClasses)\n",
    "        else:\n",
    "            image[circle] = np.random.random() * 0.5 + 0.5\n",
    "\n",
    "    labels = np.ceil(image).astype(np.int32)\n",
    "\n",
    "    norm = np.random.uniform(0, numSegClasses * noiseMax, size=image.shape)\n",
    "    noisyimage = utils.arrayutils.rescale_array(np.maximum(image, norm))\n",
    "\n",
    "    return noisyimage, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = tempfile.mkdtemp()\n",
    "\n",
    "for i in range(50):\n",
    "    im, seg = create_test_image_3d(256,256,256)\n",
    "    \n",
    "    n = nib.Nifti1Image(im, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, 'im%i.nii.gz'%i))\n",
    "    \n",
    "    n = nib.Nifti1Image(seg, np.eye(4))\n",
    "    nib.save(n, os.path.join(tempdir, 'seg%i.nii.gz'%i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "torch.Size([10, 1, 64, 64, 64]) torch.Size([10, 1, 64, 64, 64])\n"
    }
   ],
   "source": [
    "images = sorted(glob(os.path.join(tempdir,'im*.nii.gz')))\n",
    "segs = sorted(glob(os.path.join(tempdir,'seg*.nii.gz')))\n",
    "\n",
    "imtrans=transforms.Compose([\n",
    "    Rescale(),\n",
    "    AddChannel(),\n",
    "    UniformRandomPatch((64, 64, 64)),\n",
    "    ToTensor()\n",
    "])    \n",
    "\n",
    "segtrans=transforms.Compose([\n",
    "    AddChannel(),\n",
    "    UniformRandomPatch((64, 64, 64)),\n",
    "    ToTensor()\n",
    "])    \n",
    "    \n",
    "ds = NiftiDataset(images, segs, imtrans, segtrans)\n",
    "\n",
    "loader = DataLoader(ds, batch_size=10, num_workers=2, pin_memory=torch.cuda.is_available())\n",
    "im, seg = utils.mathutils.first(loader)\n",
    "print(im.shape, seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "net = networks.nets.UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    num_classes=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ")\n",
    "\n",
    "loss = networks.losses.DiceLoss(do_sigmoid=True)\n",
    "opt = torch.optim.Adam(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainEpochs = 30\n",
    "\n",
    "loss_fn = lambda i, j: loss(i[0], j)\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "trainer = create_supervised_trainer(net, opt, loss_fn, device, False)\n",
    "\n",
    "checkpoint_handler = ModelCheckpoint('./', 'net', n_saved=10, require_empty=False)\n",
    "trainer.add_event_handler(\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    handler=checkpoint_handler,\n",
    "    to_save={'net': net}\n",
    ")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    print(\"Epoch\", engine.state.epoch, \"Loss:\", engine.state.output)\n",
    "\n",
    "\n",
    "loader = DataLoader(ds, batch_size=20, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "val_loader = DataLoader(ds, batch_size=20, num_workers=8, pin_memory=torch.cuda.is_available())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_every_n_epochs = 1\n",
    "\n",
    "val_metrics = {'Mean Dice': MeanDice(add_sigmoid=True)}\n",
    "evaluator = create_supervised_evaluator(net, val_metrics, device, True,\n",
    "                                        output_transform=lambda x, y, y_pred: (y_pred[0], y))\n",
    "\n",
    "\n",
    "early_stopper = EarlyStopping(patience=4, \n",
    "                              score_function=stopping_fn_from_metric('Mean Dice'),\n",
    "                              trainer=trainer)\n",
    "evaluator.add_event_handler(event_name=Events.EPOCH_COMPLETED, handler=early_stopper)\n",
    "\n",
    "@evaluator.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_metrics(engine):\n",
    "    for name, value in engine.state.metrics.items():\n",
    "        print(\"Validation --\", name, \":\", value)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED(every=validation_every_n_epochs))\n",
    "def run_validation(engine):\n",
    "    evaluator.run(val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 1 Loss: 0.8975554704666138\nValidation -- Mean Dice : 0.11846490800380707\nEpoch 2 Loss: 0.8451039791107178\nValidation -- Mean Dice : 0.12091563045978546\nEpoch 3 Loss: 0.9355515241622925\nValidation -- Mean Dice : 0.12139833569526673\nEpoch 4 Loss: 0.843208909034729\nValidation -- Mean Dice : 0.12108306288719177\nEpoch 5 Loss: 0.8225834965705872\nValidation -- Mean Dice : 0.12179622799158096\nEpoch 6 Loss: 0.957372784614563\nValidation -- Mean Dice : 0.12193384170532226\nEpoch 7 Loss: 0.9011092782020569\nValidation -- Mean Dice : 0.1230143740773201\nEpoch 8 Loss: 0.8651387691497803\nValidation -- Mean Dice : 0.1254110112786293\nEpoch 9 Loss: 0.8767974972724915\nValidation -- Mean Dice : 0.12633273899555206\nEpoch 10 Loss: 0.8193061947822571\nValidation -- Mean Dice : 0.12657881826162337\nEpoch 11 Loss: 0.9466649293899536\nValidation -- Mean Dice : 0.12699378579854964\nEpoch 12 Loss: 0.8258659243583679\nValidation -- Mean Dice : 0.12790720015764237\nEpoch 13 Loss: 0.8661612868309021\nValidation -- Mean Dice : 0.12980296313762665\nEpoch 14 Loss: 0.8039132356643677\nValidation -- Mean Dice : 0.1311295285820961\nEpoch 15 Loss: 0.8050084114074707\nValidation -- Mean Dice : 0.13225494623184203\nEpoch 16 Loss: 0.9048625230789185\nValidation -- Mean Dice : 0.1330576255917549\nEpoch 17 Loss: 0.9179995656013489\nValidation -- Mean Dice : 0.13361359685659407\nEpoch 18 Loss: 0.8956605195999146\nValidation -- Mean Dice : 0.13432369381189346\nEpoch 19 Loss: 0.8029189705848694\nValidation -- Mean Dice : 0.13532216250896453\nEpoch 20 Loss: 0.8359838128089905\nValidation -- Mean Dice : 0.13622953295707702\nEpoch 21 Loss: 0.9225850105285645\nValidation -- Mean Dice : 0.13677610754966735\nEpoch 22 Loss: 0.7023072242736816\nValidation -- Mean Dice : 0.13693425357341765\nEpoch 23 Loss: 0.8776397705078125\nValidation -- Mean Dice : 0.13710424304008484\nEpoch 24 Loss: 0.9571539163589478\nValidation -- Mean Dice : 0.1370883911848068\nEpoch 25 Loss: 0.8877002596855164\nValidation -- Mean Dice : 0.13701471388339997\nEpoch 26 Loss: 0.817417562007904\nValidation -- Mean Dice : 0.13696834743022918\nEpoch 27 Loss: 0.8971314430236816\nValidation -- Mean Dice : 0.1371448516845703\nEpoch 28 Loss: 0.9443905353546143\nValidation -- Mean Dice : 0.13739778995513915\nEpoch 29 Loss: 0.7578094005584717\nValidation -- Mean Dice : 0.137495020031929\nEpoch 30 Loss: 0.7037953734397888\nValidation -- Mean Dice : 0.13759489357471466\n"
    }
   ],
   "source": [
    "state = trainer.run(loader, trainEpochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37564bitpytorchconda9e7dd2186ac2430b947ee08d8eff35b4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}